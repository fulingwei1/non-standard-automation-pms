#!/usr/bin/env python3
"""
åˆ†æAPIæµ‹è¯•ä¸­å‘ç°çš„runtimeé”™è¯¯
ä»æœåŠ¡å™¨æ—¥å¿—ä¸­æå–è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
"""

import re
from collections import defaultdict
from pathlib import Path
import json
from datetime import datetime


def analyze_server_log():
    """åˆ†ææœåŠ¡å™¨æ—¥å¿—ä¸­çš„é”™è¯¯"""
    log_file = Path("server.log")
    
    if not log_file.exists():
        print("âŒ æœåŠ¡å™¨æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨")
        return
    
    errors = defaultdict(list)
    
    with open(log_file, 'r', encoding='utf-8', errors='ignore') as f:
        lines = f.readlines()
    
    # åªåˆ†ææœ€è¿‘1000è¡Œ
    recent_lines = lines[-1000:] if len(lines) > 1000 else lines
    
    i = 0
    while i < len(recent_lines):
        line = recent_lines[i]
        
        # æ£€æµ‹æ•°æ®åº“é”™è¯¯
        if 'OperationalError' in line or 'no such column' in line:
            if 'no such column' in line:
                match = re.search(r'no such column: (\S+)', line)
                if match:
                    column = match.group(1)
                    errors['database_missing_columns'].append(column)
        
        # æ£€æµ‹å¯¼å…¥é”™è¯¯
        if 'ImportError' in line or 'ModuleNotFoundError' in line:
            errors['import_errors'].append(line.strip())
        
        # æ£€æµ‹AttributeError
        if 'AttributeError' in line:
            errors['attribute_errors'].append(line.strip())
        
        # æ£€æµ‹æœªå®ç°çš„API
        if 'Not Found' in line and 'Request:' in line:
            match = re.search(r'Request: (\S+)', line)
            if match:
                endpoint = match.group(1)
                errors['not_found_endpoints'].append(endpoint)
        
        # æ£€æµ‹500é”™è¯¯
        if 'INTERNAL_ERROR' in line and 'Request:' in line:
            match = re.search(r'Request: (\S+)', line)
            if match:
                endpoint = match.group(1)
                errors['internal_errors'].append(endpoint)
        
        # æ£€æµ‹å¾ªç¯å¯¼å…¥
        if 'circular import' in line.lower():
            errors['circular_imports'].append(line.strip())
        
        i += 1
    
    return errors


def analyze_test_results():
    """åˆ†ææµ‹è¯•ç»“æœ"""
    report_file = Path("data/test_core_api_report.json")
    
    if not report_file.exists():
        print("âŒ æµ‹è¯•æŠ¥å‘Šæ–‡ä»¶ä¸å­˜åœ¨")
        return None
    
    with open(report_file, 'r', encoding='utf-8') as f:
        report = json.load(f)
    
    # ç»Ÿè®¡é”™è¯¯ç±»å‹
    error_types = {
        '500_internal_error': [],
        '404_not_found': [],
        '422_validation_error': [],
        'other': []
    }
    
    for error in report['errors']:
        if '500' in error['error']:
            error_types['500_internal_error'].append(error)
        elif '404' in error['error']:
            error_types['404_not_found'].append(error)
        elif '422' in error['error']:
            error_types['422_validation_error'].append(error)
        else:
            error_types['other'].append(error)
    
    return error_types, report


def generate_analysis_report():
    """ç”Ÿæˆé”™è¯¯åˆ†ææŠ¥å‘Š"""
    print("=" * 80)
    print("APIé”™è¯¯åˆ†ææŠ¥å‘Š")
    print("=" * 80)
    print(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
    
    # 1. åˆ†ææ—¥å¿—é”™è¯¯
    print("## 1. æœåŠ¡å™¨æ—¥å¿—é”™è¯¯åˆ†æ\n")
    log_errors = analyze_server_log()
    
    if log_errors:
        if log_errors.get('database_missing_columns'):
            print("### ğŸ”´ æ•°æ®åº“åˆ—ç¼ºå¤±é”™è¯¯")
            unique_columns = set(log_errors['database_missing_columns'])
            for column in sorted(unique_columns):
                print(f"  - {column}")
            print()
        
        if log_errors.get('not_found_endpoints'):
            print("### ğŸ”´ æœªå®ç°çš„APIç«¯ç‚¹ï¼ˆ404é”™è¯¯ï¼‰")
            unique_endpoints = set(log_errors['not_found_endpoints'])
            for endpoint in sorted(unique_endpoints):
                print(f"  - {endpoint}")
            print()
        
        if log_errors.get('internal_errors'):
            print("### ğŸ”´ 500å†…éƒ¨é”™è¯¯çš„APIç«¯ç‚¹")
            unique_endpoints = set(log_errors['internal_errors'])
            for endpoint in sorted(unique_endpoints):
                print(f"  - {endpoint}")
            print()
        
        if log_errors.get('import_errors'):
            print("### ğŸ”´ å¯¼å…¥é”™è¯¯")
            for error in log_errors['import_errors'][:10]:  # æ˜¾ç¤ºå‰10ä¸ª
                print(f"  - {error[:100]}")
            print()
        
        if log_errors.get('circular_imports'):
            print("### ğŸ”´ å¾ªç¯å¯¼å…¥é”™è¯¯")
            for error in log_errors['circular_imports']:
                print(f"  - {error[:100]}")
            print()
    
    # 2. åˆ†ææµ‹è¯•ç»“æœ
    print("\n## 2. APIæµ‹è¯•ç»“æœåˆ†æ\n")
    result = analyze_test_results()
    
    if result:
        error_types, report = result
        
        print(f"æ€»æµ‹è¯•æ•°: {report['summary']['total_tests']}")
        print(f"é€šè¿‡: {report['summary']['passed']}")
        print(f"å¤±è´¥: {report['summary']['failed']}")
        print(f"æˆåŠŸç‡: {report['summary']['success_rate']}\n")
        
        print("### é”™è¯¯ç±»å‹åˆ†å¸ƒ\n")
        print(f"- 500å†…éƒ¨é”™è¯¯: {len(error_types['500_internal_error'])} ä¸ª")
        print(f"- 404æœªæ‰¾åˆ°: {len(error_types['404_not_found'])} ä¸ª")
        print(f"- 422éªŒè¯é”™è¯¯: {len(error_types['422_validation_error'])} ä¸ª")
        print(f"- å…¶ä»–é”™è¯¯: {len(error_types['other'])} ä¸ª\n")
        
        print("### æ¨¡å—é”™è¯¯è¯¦æƒ…\n")
        for module, stats in report['modules'].items():
            total = stats['total']
            passed = stats['passed']
            failed = stats['failed']
            rate = f"{(passed / total * 100):.1f}%" if total > 0 else "0%"
            status = "âœ…" if passed == total else "âš ï¸" if passed > 0 else "âŒ"
            print(f"{status} {module}: {passed}/{total} é€šè¿‡ ({rate})")
        print()
    
    # 3. ç”Ÿæˆä¿®å¤å»ºè®®
    print("\n## 3. ä¿®å¤å»ºè®®\n")
    
    suggestions = []
    
    if log_errors and log_errors.get('database_missing_columns'):
        suggestions.append({
            "priority": "ğŸ”´ P0 - ç´§æ€¥",
            "issue": "æ•°æ®åº“æ¨¡å¼ä¸åŒ¹é…",
            "description": f"å‘ç° {len(set(log_errors['database_missing_columns']))} ä¸ªç¼ºå¤±çš„æ•°æ®åº“åˆ—",
            "action": "è¿è¡Œæ•°æ®åº“è¿ç§»æˆ–æ£€æŸ¥æ¨¡å‹å®šä¹‰æ˜¯å¦ä¸æ•°æ®åº“ä¸€è‡´",
            "command": "alembic upgrade head æˆ–æ£€æŸ¥æœ€è¿‘çš„è¿ç§»è„šæœ¬"
        })
    
    if error_types and len(error_types['404_not_found']) > 10:
        suggestions.append({
            "priority": "ğŸŸ¡ P1 - é«˜",
            "issue": "å¤§é‡APIæœªå®ç°",
            "description": f"{len(error_types['404_not_found'])} ä¸ªAPIè¿”å›404",
            "action": "æ£€æŸ¥è·¯ç”±æ³¨å†Œæ˜¯å¦å®Œæ•´ï¼ŒéªŒè¯APIè·¯å¾„æ˜¯å¦æ­£ç¡®",
            "command": "æ£€æŸ¥ app/api/v1/__init__.py ä¸­çš„è·¯ç”±æ³¨å†Œ"
        })
    
    if error_types and len(error_types['500_internal_error']) > 5:
        suggestions.append({
            "priority": "ğŸ”´ P0 - ç´§æ€¥",
            "issue": "å¤§é‡500å†…éƒ¨é”™è¯¯",
            "description": f"{len(error_types['500_internal_error'])} ä¸ªAPIè¿”å›500",
            "action": "æŸ¥çœ‹è¯¦ç»†çš„æœåŠ¡å™¨æ—¥å¿—ï¼Œä¿®å¤runtimeé”™è¯¯",
            "command": "tail -f server.log | grep ERROR"
        })
    
    if log_errors and log_errors.get('import_errors'):
        suggestions.append({
            "priority": "ğŸŸ¡ P1 - é«˜",
            "issue": "æ¨¡å—å¯¼å…¥é”™è¯¯",
            "description": f"å‘ç° {len(log_errors['import_errors'])} ä¸ªå¯¼å…¥é”™è¯¯",
            "action": "æ£€æŸ¥ä¾èµ–æ˜¯å¦å®‰è£…å®Œæ•´ï¼Œæ¨¡å—è·¯å¾„æ˜¯å¦æ­£ç¡®",
            "command": "pip install -r requirements.txt"
        })
    
    for i, suggestion in enumerate(suggestions, 1):
        print(f"### å»ºè®® {i}: {suggestion['issue']}")
        print(f"**ä¼˜å…ˆçº§:** {suggestion['priority']}")
        print(f"**é—®é¢˜:** {suggestion['description']}")
        print(f"**ä¿®å¤:** {suggestion['action']}")
        print(f"**å‘½ä»¤:** `{suggestion['command']}`")
        print()
    
    # ä¿å­˜åˆ°æ–‡ä»¶
    report_content = []
    report_content.append("# APIé”™è¯¯åˆ†æä¸ä¿®å¤æŠ¥å‘Š\n")
    report_content.append(f"**ç”Ÿæˆæ—¶é—´:** {datetime.now().isoformat()}\n")
    
    report_content.append("## é—®é¢˜æ€»ç»“\n")
    
    if log_errors:
        if log_errors.get('database_missing_columns'):
            report_content.append("### æ•°æ®åº“åˆ—ç¼ºå¤±\n")
            for column in sorted(set(log_errors['database_missing_columns'])):
                report_content.append(f"- {column}\n")
            report_content.append("\n")
    
    if result:
        report_content.append("### APIæµ‹è¯•ç»“æœ\n")
        report_content.append(f"- æ€»æµ‹è¯•: {report['summary']['total_tests']}\n")
        report_content.append(f"- é€šè¿‡: {report['summary']['passed']}\n")
        report_content.append(f"- å¤±è´¥: {report['summary']['failed']}\n")
        report_content.append(f"- æˆåŠŸç‡: {report['summary']['success_rate']}\n\n")
    
    report_content.append("## ä¿®å¤å»ºè®®\n\n")
    for i, suggestion in enumerate(suggestions, 1):
        report_content.append(f"### {i}. {suggestion['issue']}\n\n")
        report_content.append(f"**ä¼˜å…ˆçº§:** {suggestion['priority']}\n\n")
        report_content.append(f"**é—®é¢˜:** {suggestion['description']}\n\n")
        report_content.append(f"**ä¿®å¤:** {suggestion['action']}\n\n")
        report_content.append(f"**å‘½ä»¤:**\n```bash\n{suggestion['command']}\n```\n\n")
    
    Path("data/api_error_analysis.md").write_text("".join(report_content), encoding='utf-8')
    
    print("\n" + "=" * 80)
    print("âœ… åˆ†æå®Œæˆï¼æŠ¥å‘Šå·²ä¿å­˜åˆ°: data/api_error_analysis.md")
    print("=" * 80)


if __name__ == "__main__":
    generate_analysis_report()

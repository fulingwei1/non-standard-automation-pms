# 多租户运维指南 (Multi-Tenant Operations Guide)

## 目录

- [1. 租户管理](#1-租户管理)
- [2. 数据备份和恢复](#2-数据备份和恢复)
- [3. 性能监控](#3-性能监控)
- [4. 故障排查](#4-故障排查)
- [5. 扩容和优化](#5-扩容和优化)
- [6. 安全运维](#6-安全运维)

---

## 1. 租户管理

### 1.1 创建租户

#### 方式1: 使用API（推荐）

```bash
# 超级管理员创建新租户
curl -X POST http://localhost:8000/api/v1/tenants \
  -H "Authorization: Bearer $SUPERUSER_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "tenant_code": "customer_a",
    "tenant_name": "客户A公司",
    "plan_type": "STANDARD",
    "max_users": 50,
    "max_roles": 20,
    "max_storage_gb": 10,
    "contact_name": "张三",
    "contact_email": "zhangsan@customer-a.com",
    "contact_phone": "13800138000"
  }'
```

**响应示例**:
```json
{
  "id": 2,
  "tenant_code": "customer_a",
  "tenant_name": "客户A公司",
  "status": "ACTIVE",
  "plan_type": "STANDARD",
  "max_users": 50,
  "created_at": "2026-02-16T08:00:00Z"
}
```

#### 方式2: 使用脚本

```python
# scripts/create_tenant.py

#!/usr/bin/env python3
"""创建新租户"""

import sys
from app.core.database import SessionLocal
from app.models.tenant import Tenant, TenantStatus, TenantPlan

def create_tenant(
    tenant_code: str,
    tenant_name: str,
    plan_type: str = "FREE",
    contact_email: str = None
):
    """创建租户"""
    
    db = SessionLocal()
    try:
        # 检查租户代码是否已存在
        existing = db.query(Tenant).filter(
            Tenant.tenant_code == tenant_code
        ).first()
        
        if existing:
            print(f"❌ Tenant '{tenant_code}' already exists (ID: {existing.id})")
            return None
        
        # 根据套餐类型设置限制
        plan_limits = {
            "FREE": {"users": 5, "roles": 5, "storage_gb": 1},
            "STANDARD": {"users": 50, "roles": 20, "storage_gb": 10},
            "ENTERPRISE": {"users": -1, "roles": -1, "storage_gb": 100},
        }
        limits = plan_limits.get(plan_type, plan_limits["FREE"])
        
        # 创建租户
        tenant = Tenant(
            tenant_code=tenant_code,
            tenant_name=tenant_name,
            status=TenantStatus.ACTIVE.value,
            plan_type=plan_type,
            max_users=limits["users"],
            max_roles=limits["roles"],
            max_storage_gb=limits["storage_gb"],
            contact_email=contact_email
        )
        
        db.add(tenant)
        db.commit()
        db.refresh(tenant)
        
        print(f"✅ Tenant created successfully!")
        print(f"   - Tenant Code: {tenant.tenant_code}")
        print(f"   - Tenant Name: {tenant.tenant_name}")
        print(f"   - Tenant ID: {tenant.id}")
        print(f"   - Plan: {tenant.plan_type}")
        
        return tenant
        
    except Exception as e:
        db.rollback()
        print(f"❌ Error creating tenant: {e}")
        raise
    finally:
        db.close()


if __name__ == "__main__":
    if len(sys.argv) < 3:
        print("Usage: python create_tenant.py <tenant_code> <tenant_name> [plan_type]")
        print("Example: python create_tenant.py customer_a '客户A公司' STANDARD")
        sys.exit(1)
    
    tenant_code = sys.argv[1]
    tenant_name = sys.argv[2]
    plan_type = sys.argv[3] if len(sys.argv) > 3 else "FREE"
    
    create_tenant(tenant_code, tenant_name, plan_type)
```

**使用**:
```bash
python scripts/create_tenant.py customer_a "客户A公司" STANDARD
```

### 1.2 查看租户信息

#### 查看所有租户

```bash
# API方式
curl -X GET http://localhost:8000/api/v1/tenants \
  -H "Authorization: Bearer $SUPERUSER_TOKEN"
```

```python
# 脚本方式
# scripts/list_tenants.py

from app.core.database import SessionLocal
from app.models.tenant import Tenant

db = SessionLocal()
tenants = db.query(Tenant).all()

print(f"\n{'ID':<5} {'Code':<15} {'Name':<30} {'Status':<10} {'Plan':<10}")
print("-" * 80)

for tenant in tenants:
    print(f"{tenant.id:<5} {tenant.tenant_code:<15} {tenant.tenant_name:<30} "
          f"{tenant.status:<10} {tenant.plan_type:<10}")

db.close()
```

#### 查看租户详情

```bash
# 查看租户使用情况
curl -X GET http://localhost:8000/api/v1/tenants/2/stats \
  -H "Authorization: Bearer $SUPERUSER_TOKEN"
```

**响应示例**:
```json
{
  "tenant_id": 2,
  "tenant_name": "客户A公司",
  "stats": {
    "user_count": 23,
    "role_count": 8,
    "project_count": 45,
    "storage_used_mb": 1250,
    "storage_limit_mb": 10240,
    "storage_usage_percent": 12.2
  },
  "limits": {
    "max_users": 50,
    "max_roles": 20,
    "max_storage_gb": 10
  }
}
```

### 1.3 更新租户

#### 更新套餐

```bash
# 升级到企业版
curl -X PATCH http://localhost:8000/api/v1/tenants/2 \
  -H "Authorization: Bearer $SUPERUSER_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "plan_type": "ENTERPRISE",
    "max_users": -1,
    "max_storage_gb": 100
  }'
```

#### 暂停租户

```bash
# 暂停租户（过期或违规）
curl -X PATCH http://localhost:8000/api/v1/tenants/2 \
  -H "Authorization: Bearer $SUPERUSER_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "status": "SUSPENDED"
  }'
```

### 1.4 删除租户

⚠️ **警告**: 删除租户是高风险操作，建议使用软删除。

#### 软删除（推荐）

```bash
# 标记为已删除
curl -X PATCH http://localhost:8000/api/v1/tenants/2 \
  -H "Authorization: Bearer $SUPERUSER_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "status": "DELETED"
  }'
```

#### 硬删除（谨慎）

```python
# scripts/delete_tenant_hard.py

import sys
from app.core.database import SessionLocal
from app.models.tenant import Tenant

def delete_tenant_hard(tenant_id: int):
    """硬删除租户及其所有数据"""
    
    db = SessionLocal()
    try:
        tenant = db.query(Tenant).filter(Tenant.id == tenant_id).first()
        if not tenant:
            print(f"❌ Tenant {tenant_id} not found")
            return False
        
        print(f"⚠️  WARNING: You are about to permanently delete:")
        print(f"   - Tenant: {tenant.tenant_name} ({tenant.tenant_code})")
        print(f"   - All associated data (users, projects, etc.)")
        
        confirm = input("\nType 'DELETE' to confirm: ")
        if confirm != "DELETE":
            print("❌ Deletion cancelled")
            return False
        
        # 1. 删除关联数据（级联删除或手动删除）
        # 注意: 需要根据 ON DELETE CASCADE 配置
        
        # 2. 删除租户
        db.delete(tenant)
        db.commit()
        
        print(f"✅ Tenant {tenant_id} deleted successfully")
        return True
        
    except Exception as e:
        db.rollback()
        print(f"❌ Error deleting tenant: {e}")
        raise
    finally:
        db.close()


if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("Usage: python delete_tenant_hard.py <tenant_id>")
        sys.exit(1)
    
    tenant_id = int(sys.argv[1])
    delete_tenant_hard(tenant_id)
```

### 1.5 租户数据导出

```python
# scripts/export_tenant_data.py

#!/usr/bin/env python3
"""导出租户数据"""

import sys
import json
from datetime import datetime
from app.core.database import SessionLocal
from app.models.tenant import Tenant
from app.models.project import Project
from app.models.user import User

def export_tenant_data(tenant_id: int, output_file: str = None):
    """导出租户的所有数据"""
    
    db = SessionLocal()
    try:
        # 获取租户
        tenant = db.query(Tenant).filter(Tenant.id == tenant_id).first()
        if not tenant:
            print(f"❌ Tenant {tenant_id} not found")
            return
        
        # 收集数据
        data = {
            "tenant": {
                "id": tenant.id,
                "tenant_code": tenant.tenant_code,
                "tenant_name": tenant.tenant_name,
                "status": tenant.status,
                "plan_type": tenant.plan_type,
            },
            "users": [
                {
                    "id": user.id,
                    "username": user.username,
                    "email": user.email,
                    "is_active": user.is_active,
                }
                for user in db.query(User).filter(User.tenant_id == tenant_id).all()
            ],
            "projects": [
                {
                    "id": project.id,
                    "name": project.name,
                    "status": project.status,
                    "created_at": project.created_at.isoformat(),
                }
                for project in db.query(Project).filter(Project.tenant_id == tenant_id).all()
            ],
            # 添加其他业务数据...
            
            "export_metadata": {
                "exported_at": datetime.utcnow().isoformat(),
                "tenant_id": tenant_id,
            }
        }
        
        # 保存到文件
        if not output_file:
            output_file = f"tenant_{tenant_id}_export_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
        
        print(f"✅ Tenant data exported to: {output_file}")
        print(f"   - Users: {len(data['users'])}")
        print(f"   - Projects: {len(data['projects'])}")
        
    finally:
        db.close()


if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("Usage: python export_tenant_data.py <tenant_id> [output_file]")
        sys.exit(1)
    
    tenant_id = int(sys.argv[1])
    output_file = sys.argv[2] if len(sys.argv) > 2 else None
    
    export_tenant_data(tenant_id, output_file)
```

---

## 2. 数据备份和恢复

### 2.1 全量备份

#### 备份整个数据库

```bash
#!/bin/bash
# scripts/backup_full.sh

# 配置
BACKUP_DIR="/var/backups/nsapm"
DATE=$(date +%Y%m%d_%H%M%S)
BACKUP_FILE="$BACKUP_DIR/full_backup_$DATE.sql"
DB_NAME="non_standard_automation"
DB_USER="nsapm_user"

# 创建备份目录
mkdir -p $BACKUP_DIR

# 执行备份
echo "Starting full database backup..."
mysqldump -u $DB_USER -p \
    --single-transaction \
    --routines \
    --triggers \
    --events \
    $DB_NAME > $BACKUP_FILE

# 压缩
gzip $BACKUP_FILE

echo "✅ Backup completed: ${BACKUP_FILE}.gz"
echo "   Size: $(du -h ${BACKUP_FILE}.gz | cut -f1)"

# 清理旧备份（保留最近7天）
find $BACKUP_DIR -name "full_backup_*.sql.gz" -mtime +7 -delete
```

#### 自动备份 (Cron)

```bash
# 添加到 crontab
crontab -e

# 每天凌晨2点执行备份
0 2 * * * /path/to/scripts/backup_full.sh >> /var/log/nsapm_backup.log 2>&1
```

### 2.2 租户级备份

#### 备份单个租户

```bash
#!/bin/bash
# scripts/backup_tenant.sh

TENANT_ID=$1
BACKUP_DIR="/var/backups/nsapm/tenants"
DATE=$(date +%Y%m%d_%H%M%S)
BACKUP_FILE="$BACKUP_DIR/tenant_${TENANT_ID}_backup_$DATE.sql"

mkdir -p $BACKUP_DIR

# 导出租户数据
echo "Backing up tenant $TENANT_ID..."

# 导出 tenants 表的单条记录
mysqldump -u nsapm_user -p non_standard_automation tenants \
    --where="id=$TENANT_ID" > $BACKUP_FILE

# 导出所有业务表（带 tenant_id 过滤）
TABLES="users roles projects rd_projects sales_contracts work_orders"

for TABLE in $TABLES; do
    mysqldump -u nsapm_user -p non_standard_automation $TABLE \
        --where="tenant_id=$TENANT_ID" \
        --no-create-info \
        --skip-add-drop-table >> $BACKUP_FILE
done

gzip $BACKUP_FILE

echo "✅ Tenant $TENANT_ID backup completed: ${BACKUP_FILE}.gz"
```

### 2.3 恢复数据

#### 恢复全量备份

```bash
# 1. 停止服务
sudo systemctl stop nsapm

# 2. 恢复数据库
gunzip < /var/backups/nsapm/full_backup_20260216_020000.sql.gz | \
    mysql -u nsapm_user -p non_standard_automation

# 3. 验证数据
mysql -u nsapm_user -p non_standard_automation -e "SELECT COUNT(*) FROM projects;"

# 4. 重启服务
sudo systemctl start nsapm
```

#### 恢复单个租户

```bash
# 1. 解压备份文件
gunzip tenant_2_backup_20260216_020000.sql.gz

# 2. 恢复数据
mysql -u nsapm_user -p non_standard_automation < tenant_2_backup_20260216_020000.sql

# 3. 验证
mysql -u nsapm_user -p -e "
    SELECT COUNT(*) FROM projects WHERE tenant_id = 2;
"
```

### 2.4 备份策略建议

| 备份类型 | 频率 | 保留时间 | 说明 |
|---------|------|----------|------|
| **全量备份** | 每天 | 7天 | 完整数据库备份 |
| **增量备份** | 每小时 | 24小时 | 二进制日志备份 |
| **租户备份** | 按需 | 30天 | 单个租户数据导出 |
| **异地备份** | 每周 | 3个月 | 灾备恢复 |

---

## 3. 性能监控

### 3.1 关键指标

#### 数据库性能指标

```bash
# 监控慢查询
mysql -u nsapm_user -p -e "
    SELECT 
        ROUND(SUM(query_time), 2) AS total_time,
        COUNT(*) AS query_count,
        LEFT(sql_text, 100) AS query_sample
    FROM mysql.slow_log
    GROUP BY query_sample
    ORDER BY total_time DESC
    LIMIT 10;
"
```

```python
# scripts/monitor_db_performance.py

#!/usr/bin/env python3
"""监控数据库性能"""

from app.core.database import SessionLocal
from sqlalchemy import text

def monitor_performance():
    """监控关键性能指标"""
    
    db = SessionLocal()
    try:
        # 1. 连接池状态
        print("\n=== Connection Pool Status ===")
        pool = db.bind.pool
        print(f"Pool size: {pool.size()}")
        print(f"Checked out connections: {pool.checkedout()}")
        print(f"Overflow connections: {pool.overflow()}")
        
        # 2. 慢查询统计
        print("\n=== Slow Queries (> 1s) ===")
        result = db.execute(text("""
            SELECT 
                COUNT(*) as count,
                AVG(query_time) as avg_time,
                MAX(query_time) as max_time,
                LEFT(sql_text, 100) as query
            FROM mysql.slow_log
            WHERE query_time > 1
            GROUP BY LEFT(sql_text, 100)
            ORDER BY count DESC
            LIMIT 5
        """))
        
        for row in result:
            print(f"Count: {row.count}, Avg: {row.avg_time}s, Max: {row.max_time}s")
            print(f"Query: {row.query}\n")
        
        # 3. 租户数据量统计
        print("\n=== Tenant Data Volume ===")
        result = db.execute(text("""
            SELECT 
                t.id,
                t.tenant_name,
                COUNT(p.id) as project_count,
                COUNT(u.id) as user_count
            FROM tenants t
            LEFT JOIN projects p ON t.id = p.tenant_id
            LEFT JOIN users u ON t.id = u.tenant_id
            GROUP BY t.id
            ORDER BY project_count DESC
        """))
        
        for row in result:
            print(f"Tenant {row.id} ({row.tenant_name}): "
                  f"{row.project_count} projects, {row.user_count} users")
        
    finally:
        db.close()


if __name__ == "__main__":
    monitor_performance()
```

#### 应用性能指标

```python
# app/core/monitoring/metrics.py

from prometheus_client import Counter, Histogram, Gauge
import time

# 请求计数器
request_count = Counter(
    'nsapm_requests_total',
    'Total HTTP requests',
    ['method', 'endpoint', 'tenant_id']
)

# 请求延迟
request_duration = Histogram(
    'nsapm_request_duration_seconds',
    'HTTP request duration in seconds',
    ['method', 'endpoint', 'tenant_id'],
    buckets=[0.01, 0.05, 0.1, 0.5, 1.0, 5.0]
)

# 租户隔离违规
tenant_violation = Counter(
    'nsapm_tenant_violations_total',
    'Total tenant isolation violations',
    ['violation_type']
)

# 租户资源使用
tenant_storage = Gauge(
    'nsapm_tenant_storage_bytes',
    'Tenant storage usage in bytes',
    ['tenant_id', 'tenant_name']
)

# 使用示例
@app.middleware("http")
async def monitor_requests(request: Request, call_next):
    """监控HTTP请求"""
    
    start_time = time.time()
    
    # 获取租户ID
    tenant_id = getattr(request.state, 'tenant_id', 'unknown')
    
    # 处理请求
    response = await call_next(request)
    
    # 记录指标
    duration = time.time() - start_time
    request_count.labels(
        method=request.method,
        endpoint=request.url.path,
        tenant_id=tenant_id
    ).inc()
    
    request_duration.labels(
        method=request.method,
        endpoint=request.url.path,
        tenant_id=tenant_id
    ).observe(duration)
    
    return response
```

### 3.2 监控告警

#### Prometheus配置

```yaml
# prometheus.yml

global:
  scrape_interval: 15s

scrape_configs:
  - job_name: 'nsapm'
    static_configs:
      - targets: ['localhost:8000']

rule_files:
  - 'alerts.yml'

alerting:
  alertmanagers:
    - static_configs:
        - targets: ['localhost:9093']
```

#### 告警规则

```yaml
# alerts.yml

groups:
  - name: nsapm_alerts
    interval: 30s
    rules:
      # 慢查询告警
      - alert: HighQueryLatency
        expr: nsapm_request_duration_seconds{quantile="0.99"} > 5
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High query latency detected"
          description: "99th percentile latency is {{ $value }}s"
      
      # 租户隔离违规
      - alert: TenantIsolationViolation
        expr: rate(nsapm_tenant_violations_total[5m]) > 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Tenant isolation violation detected"
          description: "{{ $value }} violations per second"
      
      # 存储空间告警
      - alert: TenantStorageHigh
        expr: (nsapm_tenant_storage_bytes / nsapm_tenant_storage_limit_bytes) > 0.9
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "Tenant storage usage high"
          description: "Tenant {{ $labels.tenant_name }} is using {{ $value }}% of storage"
```

### 3.3 日志监控

#### 配置日志

```python
# app/core/logging_config.py

import logging
import logging.handlers

# 配置日志格式
LOG_FORMAT = '%(asctime)s - %(name)s - %(levelname)s - [tenant:%(tenant_id)s] - %(message)s'

# 创建日志适配器（自动添加租户ID）
class TenantLogAdapter(logging.LoggerAdapter):
    """租户日志适配器"""
    
    def process(self, msg, kwargs):
        from app.core.middleware.tenant_middleware import get_current_tenant_id
        
        tenant_id = get_current_tenant_id() or 'system'
        
        extra = kwargs.get('extra', {})
        extra['tenant_id'] = tenant_id
        kwargs['extra'] = extra
        
        return msg, kwargs


# 配置日志处理器
def setup_logging():
    """配置日志系统"""
    
    # 文件处理器（按租户分离）
    tenant_handler = logging.handlers.RotatingFileHandler(
        'logs/tenant.log',
        maxBytes=10*1024*1024,  # 10MB
        backupCount=10
    )
    tenant_handler.setFormatter(logging.Formatter(LOG_FORMAT))
    
    # 错误日志处理器
    error_handler = logging.handlers.RotatingFileHandler(
        'logs/error.log',
        maxBytes=10*1024*1024,
        backupCount=10
    )
    error_handler.setLevel(logging.ERROR)
    error_handler.setFormatter(logging.Formatter(LOG_FORMAT))
    
    # 根日志配置
    root_logger = logging.getLogger()
    root_logger.setLevel(logging.INFO)
    root_logger.addHandler(tenant_handler)
    root_logger.addHandler(error_handler)
```

#### 使用日志

```python
# 在代码中使用
from app.core.logging_config import TenantLogAdapter
import logging

logger = TenantLogAdapter(logging.getLogger(__name__), {})

# 自动记录租户ID
logger.info("User created product")
# 输出: 2026-02-16 10:30:00 - app.api.products - INFO - [tenant:1] - User created product
```

---

## 4. 故障排查

### 4.1 常见问题诊断

#### 问题1: 租户数据泄露

**症状**: 用户可以看到其他租户的数据

**诊断步骤**:
```python
# 1. 检查TenantQuery是否生效
from app.core.database import SessionLocal
print(SessionLocal.kw.get('query_cls'))  # 应该是 TenantQuery

# 2. 检查中间件顺序
from app.main import app
print([m.cls.__name__ for m in app.user_middleware])  
# 应该包含 TenantContextMiddleware

# 3. 检查租户上下文
from app.core.middleware.tenant_middleware import get_current_tenant_id
print(get_current_tenant_id())  # 应该返回当前租户ID

# 4. 手动执行查询测试
db = SessionLocal()
from app.models.project import Project
projects = db.query(Project).all()
print([p.tenant_id for p in projects])  # 应该都是同一个租户
```

**解决方案**:
```python
# 确保 main.py 配置正确
from app.core.database.tenant_query import TenantQuery
from app.core.middleware.tenant_middleware import TenantContextMiddleware

# Session配置
SessionLocal = sessionmaker(
    bind=engine,
    query_cls=TenantQuery,  # ✅ 必须
    autocommit=False,
    autoflush=False,
)

# 中间件配置
app.add_middleware(TenantContextMiddleware)  # ✅ 必须
```

#### 问题2: 查询性能下降

**症状**: 添加租户过滤后查询变慢

**诊断步骤**:
```sql
-- 1. 检查查询计划
EXPLAIN SELECT * FROM projects 
WHERE tenant_id = 1 AND status = 'active';

-- 2. 检查索引
SHOW INDEX FROM projects;

-- 3. 分析慢查询
SELECT 
    sql_text,
    query_time,
    rows_examined,
    rows_sent
FROM mysql.slow_log
WHERE query_time > 1
ORDER BY query_time DESC
LIMIT 10;
```

**解决方案**:
```sql
-- 添加缺失的索引
CREATE INDEX idx_projects_tenant_status ON projects(tenant_id, status);

-- 优化查询
-- ❌ 错误: 没有使用索引
SELECT * FROM projects WHERE status = 'active' AND tenant_id = 1;

-- ✅ 正确: 索引列顺序正确
SELECT * FROM projects WHERE tenant_id = 1 AND status = 'active';
```

#### 问题3: 连接池耗尽

**症状**: `QueuePool limit of size X overflow Y reached`

**诊断**:
```python
# 检查连接池状态
from app.core.database import engine
pool = engine.pool

print(f"Pool size: {pool.size()}")
print(f"Checked out: {pool.checkedout()}")
print(f"Overflow: {pool.overflow()}")
print(f"Max overflow: {pool._max_overflow}")
```

**解决方案**:
```python
# 增加连接池大小
engine = create_engine(
    DATABASE_URL,
    pool_size=50,      # 增加基础池大小
    max_overflow=100,  # 增加溢出连接数
    pool_timeout=30,
    pool_recycle=3600,
)

# 或者，检查是否有连接泄漏
# 确保所有 db.close() 正确调用
```

### 4.2 日志分析

#### 查找租户隔离违规

```bash
# 查找跨租户访问尝试
grep "tenant_id" logs/tenant.log | grep "violation"

# 查找慢查询
grep "query_time" logs/app.log | awk '$6 > 1'  # 超过1秒的查询
```

#### 分析租户活跃度

```bash
# 统计每个租户的请求数
awk -F'[tenant:|]' '/tenant:/ {count[$2]++} END {for(t in count) print t, count[t]}' \
    logs/tenant.log | sort -k2 -rn
```

### 4.3 数据完整性检查

```python
# scripts/check_data_integrity.py

#!/usr/bin/env python3
"""检查数据完整性"""

from sqlalchemy import text
from app.core.database import SessionLocal

def check_integrity():
    """检查租户数据完整性"""
    
    db = SessionLocal()
    issues = []
    
    try:
        print("\n=== Data Integrity Check ===\n")
        
        # 1. 检查孤立数据（tenant_id = NULL）
        tables = ['projects', 'users', 'work_orders', 'tasks']
        
        for table in tables:
            null_count = db.execute(
                text(f"SELECT COUNT(*) FROM {table} WHERE tenant_id IS NULL")
            ).scalar()
            
            if null_count > 0:
                issue = f"{table}: {null_count} rows with NULL tenant_id"
                issues.append(issue)
                print(f"❌ {issue}")
            else:
                print(f"✅ {table}: All rows have tenant_id")
        
        # 2. 检查外键完整性
        print("\n=== Foreign Key Integrity ===\n")
        
        for table in tables:
            invalid_fk = db.execute(
                text(f"""
                    SELECT COUNT(*) FROM {table} t
                    LEFT JOIN tenants tn ON t.tenant_id = tn.id
                    WHERE t.tenant_id IS NOT NULL AND tn.id IS NULL
                """)
            ).scalar()
            
            if invalid_fk > 0:
                issue = f"{table}: {invalid_fk} rows with invalid tenant_id"
                issues.append(issue)
                print(f"❌ {issue}")
            else:
                print(f"✅ {table}: All foreign keys valid")
        
        # 3. 检查超级管理员数据一致性
        print("\n=== Superuser Consistency ===\n")
        
        inconsistent = db.execute(
            text("""
                SELECT id, username, is_superuser, tenant_id
                FROM users
                WHERE (is_superuser = TRUE AND tenant_id IS NOT NULL)
                   OR (is_superuser = FALSE AND tenant_id IS NULL)
            """)
        ).fetchall()
        
        if inconsistent:
            for user in inconsistent:
                issue = f"User {user.id} ({user.username}): is_superuser={user.is_superuser}, tenant_id={user.tenant_id}"
                issues.append(issue)
                print(f"❌ {issue}")
        else:
            print("✅ All users have consistent superuser status")
        
        # 输出总结
        print(f"\n=== Summary ===")
        if issues:
            print(f"❌ Found {len(issues)} issues:")
            for issue in issues:
                print(f"  - {issue}")
            return False
        else:
            print("✅ All checks passed!")
            return True
        
    finally:
        db.close()


if __name__ == "__main__":
    success = check_integrity()
    exit(0 if success else 1)
```

---

## 5. 扩容和优化

### 5.1 数据库扩容

#### 垂直扩容（增加资源）

```bash
# 1. 备份数据
bash scripts/backup_full.sh

# 2. 停止服务
sudo systemctl stop nsapm

# 3. 调整MySQL配置 (/etc/mysql/my.cnf)
[mysqld]
innodb_buffer_pool_size = 4G      # 增加缓冲池（原1G）
max_connections = 500              # 增加最大连接数（原200）
query_cache_size = 256M            # 查询缓存
innodb_log_file_size = 512M       # 日志文件大小

# 4. 重启MySQL
sudo systemctl restart mysql

# 5. 验证配置
mysql -u root -p -e "SHOW VARIABLES LIKE 'innodb_buffer_pool_size';"

# 6. 重启服务
sudo systemctl start nsapm
```

#### 水平扩容（读写分离）

```python
# app/core/database.py

from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker

# 主库（写）
WRITE_DATABASE_URL = "mysql+pymysql://user:pass@master:3306/nsapm"
write_engine = create_engine(WRITE_DATABASE_URL, pool_size=20)

# 从库（读）
READ_DATABASE_URL = "mysql+pymysql://user:pass@slave:3306/nsapm"
read_engine = create_engine(READ_DATABASE_URL, pool_size=50)

# 写Session
WriteSession = sessionmaker(bind=write_engine, query_cls=TenantQuery)

# 读Session
ReadSession = sessionmaker(bind=read_engine, query_cls=TenantQuery)


# 在API中使用
@router.get("/projects")
async def list_projects(db: Session = Depends(get_read_db)):  # 读库
    projects = db.query(Project).all()
    return projects


@router.post("/projects")
async def create_project(
    data: ProjectCreate,
    db: Session = Depends(get_write_db)  # 写库
):
    project = Project(**data.dict())
    db.add(project)
    db.commit()
    return project
```

### 5.2 缓存优化

#### Redis缓存配置

```python
# app/core/cache.py

import redis
import pickle
from functools import wraps

# Redis连接池
redis_pool = redis.ConnectionPool.from_url(
    'redis://localhost:6379/0',
    max_connections=50
)
redis_client = redis.Redis(connection_pool=redis_pool)


def cache_by_tenant(expire=300):
    """租户级别的缓存装饰器"""
    
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            # 获取当前租户ID
            from app.core.middleware.tenant_middleware import get_current_tenant_id
            tenant_id = get_current_tenant_id()
            
            # 生成缓存键
            cache_key = f"tenant:{tenant_id}:func:{func.__name__}:args:{args}:kwargs:{kwargs}"
            
            # 尝试从缓存获取
            cached = redis_client.get(cache_key)
            if cached:
                return pickle.loads(cached)
            
            # 执行函数
            result = await func(*args, **kwargs)
            
            # 写入缓存
            redis_client.setex(cache_key, expire, pickle.dumps(result))
            
            return result
        
        return wrapper
    return decorator


# 使用示例
@cache_by_tenant(expire=600)  # 缓存10分钟
async def get_tenant_config(db: Session, current_user: User):
    """获取租户配置（高频读取）"""
    config = db.query(TenantConfig).filter(
        TenantConfig.tenant_id == current_user.tenant_id
    ).first()
    return config
```

### 5.3 索引优化

```sql
-- 分析表使用情况
SELECT 
    TABLE_NAME,
    TABLE_ROWS,
    AVG_ROW_LENGTH,
    DATA_LENGTH / 1024 / 1024 AS data_mb,
    INDEX_LENGTH / 1024 / 1024 AS index_mb
FROM information_schema.TABLES
WHERE TABLE_SCHEMA = 'non_standard_automation'
ORDER BY DATA_LENGTH DESC;

-- 查找未使用的索引
SELECT 
    s.table_name,
    s.index_name,
    s.cardinality
FROM information_schema.statistics s
LEFT JOIN information_schema.index_statistics i 
    ON s.table_schema = i.table_schema
    AND s.table_name = i.table_name
    AND s.index_name = i.index_name
WHERE s.table_schema = 'non_standard_automation'
  AND i.index_name IS NULL
  AND s.index_name != 'PRIMARY';

-- 删除未使用的索引（谨慎）
-- DROP INDEX idx_unused ON table_name;
```

---

## 6. 安全运维

### 6.1 审计日志

```python
# app/core/audit.py

from datetime import datetime
from app.models.audit_log import AuditLog
from app.core.middleware.tenant_middleware import get_current_tenant_id

def log_audit(
    action: str,
    resource_type: str,
    resource_id: int,
    user_id: int,
    details: dict = None
):
    """记录审计日志"""
    
    db = SessionLocal()
    try:
        log = AuditLog(
            tenant_id=get_current_tenant_id(),
            action=action,
            resource_type=resource_type,
            resource_id=resource_id,
            user_id=user_id,
            details=details,
            created_at=datetime.utcnow()
        )
        
        db.add(log)
        db.commit()
        
    finally:
        db.close()


# 使用示例
@router.delete("/projects/{project_id}")
async def delete_project(
    project_id: int,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_active_user)
):
    project = db.query(Project).filter(Project.id == project_id).first()
    
    # 记录审计日志
    log_audit(
        action="DELETE",
        resource_type="Project",
        resource_id=project_id,
        user_id=current_user.id,
        details={
            "project_name": project.name,
            "tenant_id": project.tenant_id
        }
    )
    
    # 删除项目
    db.delete(project)
    db.commit()
```

### 6.2 敏感数据脱敏

```python
# scripts/mask_sensitive_data.py

#!/usr/bin/env python3
"""脱敏敏感数据（用于导出测试数据）"""

import hashlib
from app.core.database import SessionLocal
from app.models.user import User

def mask_sensitive_data():
    """脱敏用户敏感信息"""
    
    db = SessionLocal()
    try:
        users = db.query(User).all()
        
        for user in users:
            # 邮箱脱敏
            user.email = f"user{user.id}@example.com"
            
            # 手机号脱敏
            if user.phone:
                user.phone = "138****" + user.phone[-4:]
            
            # 密码重置
            user.hashed_password = hashlib.sha256(b"Password123").hexdigest()
        
        db.commit()
        print("✅ Sensitive data masked successfully")
        
    finally:
        db.close()


if __name__ == "__main__":
    confirm = input("⚠️  This will mask all user data. Continue? (yes/no): ")
    if confirm == "yes":
        mask_sensitive_data()
```

---

## 附录

### A. 运维脚本清单

```bash
scripts/
├── backup_full.sh              # 全量备份
├── backup_tenant.sh            # 租户备份
├── create_tenant.py            # 创建租户
├── delete_tenant_hard.py       # 删除租户
├── export_tenant_data.py       # 导出租户数据
├── monitor_db_performance.py   # 性能监控
├── check_data_integrity.py     # 数据完整性检查
└── mask_sensitive_data.py      # 数据脱敏
```

### B. 常用命令

```bash
# 查看租户列表
python scripts/list_tenants.py

# 创建租户
python scripts/create_tenant.py customer_a "客户A公司" STANDARD

# 备份租户
bash scripts/backup_tenant.sh 2

# 性能监控
python scripts/monitor_db_performance.py

# 数据完整性检查
python scripts/check_data_integrity.py
```

### C. 应急联系

- **技术支持**: tech-support@example.com
- **运维值班**: ops-oncall@example.com
- **紧急电话**: 400-xxx-xxxx

---

**文档版本**: 1.0  
**最后更新**: 2026-02-16  
**维护团队**: Team 6 - 文档和部署

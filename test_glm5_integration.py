#!/usr/bin/env python3
"""
GLM-5 é›†æˆæµ‹è¯•è„šæœ¬

æµ‹è¯•é¡¹ç›®:
1. zai-sdk å¯¼å…¥æµ‹è¯•
2. Mock æ¨¡å¼æµ‹è¯•ï¼ˆæ— API Keyï¼‰
3. çœŸå®APIæµ‹è¯•ï¼ˆéœ€è¦é…ç½® ZHIPU_API_KEYï¼‰
4. æ€è€ƒæ¨¡å¼æµ‹è¯•
5. æ€§èƒ½å¯¹æ¯”æµ‹è¯•ï¼ˆGLM-5 vs Kimi vs GPT-4ï¼‰
"""

import os
import sys
import time
from typing import Dict, Any

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from app.services.ai_client_service import AIClientService


class Colors:
    """ç»ˆç«¯é¢œè‰²"""
    GREEN = '\033[92m'
    RED = '\033[91m'
    YELLOW = '\033[93m'
    BLUE = '\033[94m'
    RESET = '\033[0m'


def print_test_header(title: str):
    """æ‰“å°æµ‹è¯•æ ‡é¢˜"""
    print(f"\n{'='*60}")
    print(f"{Colors.BLUE}{title}{Colors.RESET}")
    print(f"{'='*60}\n")


def print_success(message: str):
    """æ‰“å°æˆåŠŸæ¶ˆæ¯"""
    print(f"{Colors.GREEN}âœ… {message}{Colors.RESET}")


def print_error(message: str):
    """æ‰“å°é”™è¯¯æ¶ˆæ¯"""
    print(f"{Colors.RED}âŒ {message}{Colors.RESET}")


def print_warning(message: str):
    """æ‰“å°è­¦å‘Šæ¶ˆæ¯"""
    print(f"{Colors.YELLOW}âš ï¸  {message}{Colors.RESET}")


def test_sdk_import():
    """æµ‹è¯• zai-sdk å¯¼å…¥"""
    print_test_header("æµ‹è¯• 1: zai-sdk å¯¼å…¥æµ‹è¯•")
    
    try:
        from zai import ZhipuAiClient
        print_success("zai-sdk å¯¼å…¥æˆåŠŸ")
        print(f"   ZhipuAiClient: {ZhipuAiClient}")
        return True
    except ImportError as e:
        print_error(f"zai-sdk å¯¼å…¥å¤±è´¥: {e}")
        print_warning("è¯·è¿è¡Œ: pip3 install zai-sdk")
        return False


def test_mock_mode():
    """æµ‹è¯• Mock æ¨¡å¼"""
    print_test_header("æµ‹è¯• 2: Mock æ¨¡å¼æµ‹è¯•ï¼ˆæ— API Keyï¼‰")
    
    # ä¸´æ—¶æ¸…ç©ºAPI Keys
    original_zhipu = os.environ.get("ZHIPU_API_KEY", "")
    original_openai = os.environ.get("OPENAI_API_KEY", "")
    original_kimi = os.environ.get("KIMI_API_KEY", "")
    
    os.environ["ZHIPU_API_KEY"] = ""
    os.environ["OPENAI_API_KEY"] = ""
    os.environ["KIMI_API_KEY"] = ""
    
    try:
        client = AIClientService()
        
        # æµ‹è¯•æ–¹æ¡ˆç”Ÿæˆ
        response = client.generate_solution(
            prompt="è®¾è®¡ä¸€å¥—æ±½è½¦é›¶éƒ¨ä»¶è£…é…çº¿",
            model="glm-5"
        )
        
        print(f"æ¨¡å‹: {response['model']}")
        print(f"Tokenä½¿ç”¨: {response['usage']['total_tokens']}")
        print(f"å†…å®¹é¢„è§ˆ: {response['content'][:100]}...")
        
        if response['model'] == 'glm-5-mock':
            print_success("Mock æ¨¡å¼å·¥ä½œæ­£å¸¸")
            return True
        else:
            print_error(f"é¢„æœŸ 'glm-5-mock'ï¼Œå®é™…: {response['model']}")
            return False
            
    except Exception as e:
        print_error(f"Mock æ¨¡å¼æµ‹è¯•å¤±è´¥: {e}")
        return False
    finally:
        # æ¢å¤åŸå§‹API Keys
        os.environ["ZHIPU_API_KEY"] = original_zhipu
        os.environ["OPENAI_API_KEY"] = original_openai
        os.environ["KIMI_API_KEY"] = original_kimi


def test_real_api():
    """æµ‹è¯•çœŸå® API è°ƒç”¨"""
    print_test_header("æµ‹è¯• 3: çœŸå® GLM-5 API æµ‹è¯•")
    
    zhipu_key = os.environ.get("ZHIPU_API_KEY", "")
    
    if not zhipu_key or zhipu_key == "your_zhipu_api_key_here":
        print_warning("æœªé…ç½® ZHIPU_API_KEYï¼Œè·³è¿‡çœŸå®APIæµ‹è¯•")
        print_warning("é…ç½®æ–¹å¼: export ZHIPU_API_KEY=your_actual_key")
        return None
    
    try:
        client = AIClientService()
        
        print("æ­£åœ¨è°ƒç”¨ GLM-5 API...")
        start_time = time.time()
        
        response = client.generate_solution(
            prompt="è¯·ç”¨ä¸€å¥è¯ä»‹ç»éæ ‡è‡ªåŠ¨åŒ–è¡Œä¸š",
            model="glm-5",
            temperature=0.7,
            max_tokens=100
        )
        
        elapsed = time.time() - start_time
        
        print(f"æ¨¡å‹: {response['model']}")
        print(f"å“åº”æ—¶é—´: {elapsed:.2f}ç§’")
        print(f"Tokenä½¿ç”¨: {response['usage']}")
        print(f"å›å¤å†…å®¹:\n{response['content']}")
        
        if 'reasoning' in response:
            print(f"\næ€è€ƒè¿‡ç¨‹:\n{response['reasoning']}")
        
        print_success(f"GLM-5 API è°ƒç”¨æˆåŠŸ (è€—æ—¶ {elapsed:.2f}s)")
        return True
        
    except Exception as e:
        print_error(f"GLM-5 API è°ƒç”¨å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def test_thinking_mode():
    """æµ‹è¯•æ€è€ƒæ¨¡å¼"""
    print_test_header("æµ‹è¯• 4: æ€è€ƒæ¨¡å¼æµ‹è¯•")
    
    zhipu_key = os.environ.get("ZHIPU_API_KEY", "")
    
    if not zhipu_key or zhipu_key == "your_zhipu_api_key_here":
        print_warning("æœªé…ç½® ZHIPU_API_KEYï¼Œè·³è¿‡æ€è€ƒæ¨¡å¼æµ‹è¯•")
        return None
    
    try:
        client = AIClientService()
        
        # å¤æ‚ä»»åŠ¡åº”è¯¥è‡ªåŠ¨å¯ç”¨æ€è€ƒæ¨¡å¼
        complex_prompt = """
        è®¾è®¡ä¸€å¥—æ™ºèƒ½åŒ–æ±½è½¦é›¶éƒ¨ä»¶è£…é…çº¿ï¼Œè¦æ±‚ï¼š
        1. ç”Ÿäº§èŠ‚æ‹: 60ç§’/ä»¶
        2. è‡ªåŠ¨åŒ–ç¨‹åº¦: 95%ä»¥ä¸Š
        3. åŒ…å«è§†è§‰æ£€æµ‹å’Œæœºå™¨äººè£…é…
        4. éœ€è¦è€ƒè™‘æˆæœ¬ä¼˜åŒ–
        """
        
        print("æ­£åœ¨è°ƒç”¨ GLM-5ï¼ˆå¤æ‚ä»»åŠ¡ï¼Œåº”å¯ç”¨æ€è€ƒæ¨¡å¼ï¼‰...")
        start_time = time.time()
        
        response = client.generate_solution(
            prompt=complex_prompt,
            model="glm-5",
            temperature=0.7,
            max_tokens=500
        )
        
        elapsed = time.time() - start_time
        
        print(f"å“åº”æ—¶é—´: {elapsed:.2f}ç§’")
        print(f"Tokenä½¿ç”¨: {response['usage']}")
        
        if 'reasoning' in response:
            print_success("âœ¨ æ€è€ƒæ¨¡å¼å·²å¯ç”¨")
            print(f"æ€è€ƒè¿‡ç¨‹é•¿åº¦: {len(response['reasoning'])} å­—ç¬¦")
        else:
            print_warning("æ€è€ƒæ¨¡å¼æœªå¯ç”¨ï¼ˆå¯èƒ½æ˜¯ç®€å•ä»»åŠ¡ï¼‰")
        
        print(f"\næ–¹æ¡ˆå†…å®¹:\n{response['content'][:200]}...")
        
        return True
        
    except Exception as e:
        print_error(f"æ€è€ƒæ¨¡å¼æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_model_comparison():
    """æµ‹è¯•å¤šæ¨¡å‹å¯¹æ¯”"""
    print_test_header("æµ‹è¯• 5: æ¨¡å‹æ€§èƒ½å¯¹æ¯”")
    
    models = []
    
    # æ£€æŸ¥å¯ç”¨æ¨¡å‹
    if os.environ.get("ZHIPU_API_KEY", "") and os.environ.get("ZHIPU_API_KEY") != "your_zhipu_api_key_here":
        models.append("glm-5")
    if os.environ.get("OPENAI_API_KEY", ""):
        models.append("gpt-4")
    if os.environ.get("KIMI_API_KEY", ""):
        models.append("kimi")
    
    if not models:
        print_warning("æœªé…ç½®ä»»ä½• API Keyï¼Œè·³è¿‡æ¨¡å‹å¯¹æ¯”æµ‹è¯•")
        return None
    
    print(f"å¯ç”¨æ¨¡å‹: {', '.join(models)}\n")
    
    test_prompt = "è¯·ç”¨ä¸€å¥è¯ä»‹ç»éæ ‡è‡ªåŠ¨åŒ–è¡Œä¸šçš„æ ¸å¿ƒä»·å€¼"
    
    results = {}
    
    for model in models:
        try:
            client = AIClientService()
            
            print(f"æµ‹è¯• {model}...")
            start_time = time.time()
            
            response = client.generate_solution(
                prompt=test_prompt,
                model=model,
                temperature=0.7,
                max_tokens=100
            )
            
            elapsed = time.time() - start_time
            
            results[model] = {
                "time": elapsed,
                "tokens": response['usage']['total_tokens'],
                "content": response['content']
            }
            
            print(f"  â±ï¸  å“åº”æ—¶é—´: {elapsed:.2f}ç§’")
            print(f"  ğŸ“Š Tokenä½¿ç”¨: {response['usage']['total_tokens']}")
            print()
            
        except Exception as e:
            print_error(f"  {model} æµ‹è¯•å¤±è´¥: {e}")
    
    # æ‰“å°å¯¹æ¯”ç»“æœ
    if results:
        print("\n" + "="*60)
        print("æ€§èƒ½å¯¹æ¯”æ€»ç»“:")
        print("="*60)
        
        for model, result in results.items():
            print(f"\n{model}:")
            print(f"  å“åº”æ—¶é—´: {result['time']:.2f}ç§’")
            print(f"  Tokenä½¿ç”¨: {result['tokens']}")
            print(f"  å›å¤: {result['content'][:80]}...")
        
        # æ‰¾å‡ºæœ€å¿«çš„æ¨¡å‹
        fastest = min(results.items(), key=lambda x: x[1]['time'])
        print(f"\nğŸ† æœ€å¿«æ¨¡å‹: {fastest[0]} ({fastest[1]['time']:.2f}ç§’)")
        
        return True
    
    return False


def main():
    """ä¸»æµ‹è¯•æµç¨‹"""
    print(f"\n{Colors.BLUE}{'='*60}")
    print("GLM-5 é›†æˆæµ‹è¯•")
    print(f"{'='*60}{Colors.RESET}\n")
    
    results = {
        "SDKå¯¼å…¥": test_sdk_import(),
        "Mockæ¨¡å¼": test_mock_mode(),
        "çœŸå®API": test_real_api(),
        "æ€è€ƒæ¨¡å¼": test_thinking_mode(),
        "æ¨¡å‹å¯¹æ¯”": test_model_comparison()
    }
    
    # æ‰“å°æµ‹è¯•æ€»ç»“
    print(f"\n{Colors.BLUE}{'='*60}")
    print("æµ‹è¯•æ€»ç»“")
    print(f"{'='*60}{Colors.RESET}\n")
    
    for test_name, result in results.items():
        if result is True:
            print_success(f"{test_name}: é€šè¿‡")
        elif result is False:
            print_error(f"{test_name}: å¤±è´¥")
        else:
            print_warning(f"{test_name}: è·³è¿‡")
    
    # ç»Ÿè®¡
    passed = sum(1 for r in results.values() if r is True)
    failed = sum(1 for r in results.values() if r is False)
    skipped = sum(1 for r in results.values() if r is None)
    
    print(f"\næ€»è®¡: {passed} é€šè¿‡, {failed} å¤±è´¥, {skipped} è·³è¿‡")
    
    # è¿”å›çŠ¶æ€ç 
    return 0 if failed == 0 else 1


if __name__ == "__main__":
    sys.exit(main())
